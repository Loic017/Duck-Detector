{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN MobileNetV3 Large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stuff\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torchsummary import summary\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = stuff.IMAGES_FOLDER\n",
    "BALL_CSV = stuff.BALL_CSV\n",
    "LINE_CSV = stuff.LINE_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, ball_df, line_df, transform=None):\n",
    "        self.images = images\n",
    "        self.ball_df = ball_df\n",
    "        self.line_df = line_df\n",
    "\n",
    "        self.boxes, self.labels, self.imgs = self.organise_data(\n",
    "            images, ball_df, line_df\n",
    "        )\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(np.array(self.imgs[idx]), dtype=torch.float32)\n",
    "        box = self.transform(self.boxes[idx], dtype=torch.int64)\n",
    "        label = self.transform(self.labels[idx], dtype=torch.int64)\n",
    "\n",
    "        return image, box, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def organise_data(self, images, ball_df, line_df):\n",
    "        imgs = []\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for i, img in enumerate(images):\n",
    "            ball_topleft = [ball_df.iloc[i][\"x\"], ball_df.iloc[i][\"y\"]]\n",
    "            ball_bottomright = [\n",
    "                ball_df.iloc[i][\"x\"] + (ball_df.iloc[i][\"width\"]),\n",
    "                ball_df.iloc[i][\"y\"] + (ball_df.iloc[i][\"height\"]),\n",
    "            ]\n",
    "            ball_data = [ball_topleft, ball_bottomright]\n",
    "\n",
    "            line_topleft = [line_df.iloc[i][\"x\"], line_df.iloc[i][\"y\"]]\n",
    "            line_bottomright = [\n",
    "                line_df.iloc[i][\"x\"] + (line_df.iloc[i][\"width\"]),\n",
    "                line_df.iloc[i][\"y\"] + (line_df.iloc[i][\"height\"]),\n",
    "            ]\n",
    "            line_data = [line_topleft, line_bottomright]\n",
    "\n",
    "            boxes.append([ball_data, line_data])\n",
    "            labels.append([1, 2])\n",
    "\n",
    "            new_img = np.transpose(img, (2, 0, 1))\n",
    "            imgs.append(new_img)\n",
    "\n",
    "        return boxes, labels, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(IMAGE_FOLDER, IMAGE_FILE_TYPE):\n",
    "    image_files = []\n",
    "    for file in os.listdir(IMAGE_FOLDER):\n",
    "        if file.endswith(IMAGE_FILE_TYPE):\n",
    "            image_files.append(file)\n",
    "    return image_files\n",
    "\n",
    "\n",
    "def load_image_files(image_files, IMAGE_FOLDER):\n",
    "    images = []\n",
    "    for file in image_files:\n",
    "        image = cv2.imread(IMAGE_FOLDER + \"/\" + file)\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 280, 504, 3)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files = get_image_files(IMAGE_FOLDER, \"jpg\")\n",
    "images = load_image_files(image_files, IMAGE_FOLDER)\n",
    "np.array(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_df = pd.read_csv(BALL_CSV)\n",
    "line_df = pd.read_csv(LINE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(images, ball_df, line_df, torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, val_inds,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loicl\\Documents\\Enlightenment\\Programming\\Artificial Intelligence\\Object Detection\\Over-the-line--Football-line-detector\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to C:\\Users\\loicl/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_large-8738ca79.pth\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 280, 504])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fasterrcnn_mobilenet_v3_large_fpn(pretrained=False)\n",
    "input_size = dataset[0][0].shape\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
